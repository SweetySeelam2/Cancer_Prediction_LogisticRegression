{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a6b8882",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd84c779",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the dataset\n",
    "df= pd.read_csv(r'C:\\Users\\sweet\\Desktop\\DataScience\\MS office files\\CSV files\\Cancer prediction dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f0fe41c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Overview of the first 5 rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c753754c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 33 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       569 non-null    int64  \n",
      " 1   diagnosis                569 non-null    object \n",
      " 2   radius_mean              569 non-null    float64\n",
      " 3   texture_mean             569 non-null    float64\n",
      " 4   perimeter_mean           569 non-null    float64\n",
      " 5   area_mean                569 non-null    float64\n",
      " 6   smoothness_mean          569 non-null    float64\n",
      " 7   compactness_mean         569 non-null    float64\n",
      " 8   concavity_mean           569 non-null    float64\n",
      " 9   concave points_mean      569 non-null    float64\n",
      " 10  symmetry_mean            569 non-null    float64\n",
      " 11  fractal_dimension_mean   569 non-null    float64\n",
      " 12  radius_se                569 non-null    float64\n",
      " 13  texture_se               569 non-null    float64\n",
      " 14  perimeter_se             569 non-null    float64\n",
      " 15  area_se                  569 non-null    float64\n",
      " 16  smoothness_se            569 non-null    float64\n",
      " 17  compactness_se           569 non-null    float64\n",
      " 18  concavity_se             569 non-null    float64\n",
      " 19  concave points_se        569 non-null    float64\n",
      " 20  symmetry_se              569 non-null    float64\n",
      " 21  fractal_dimension_se     569 non-null    float64\n",
      " 22  radius_worst             569 non-null    float64\n",
      " 23  texture_worst            569 non-null    float64\n",
      " 24  perimeter_worst          569 non-null    float64\n",
      " 25  area_worst               569 non-null    float64\n",
      " 26  smoothness_worst         569 non-null    float64\n",
      " 27  compactness_worst        569 non-null    float64\n",
      " 28  concavity_worst          569 non-null    float64\n",
      " 29  concave points_worst     569 non-null    float64\n",
      " 30  symmetry_worst           569 non-null    float64\n",
      " 31  fractal_dimension_worst  569 non-null    float64\n",
      " 32  Unnamed: 32              0 non-null      float64\n",
      "dtypes: float64(31), int64(1), object(1)\n",
      "memory usage: 146.8+ KB\n"
     ]
    }
   ],
   "source": [
    "#Check the data structures\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe0a0c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.037183e+07</td>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>...</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.250206e+08</td>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>...</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.670000e+03</td>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>...</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.692180e+05</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>...</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.060240e+05</td>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>...</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.813129e+06</td>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>...</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.113205e+08</td>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>...</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  radius_mean  texture_mean  perimeter_mean    area_mean  \\\n",
       "count  5.690000e+02   569.000000    569.000000      569.000000   569.000000   \n",
       "mean   3.037183e+07    14.127292     19.289649       91.969033   654.889104   \n",
       "std    1.250206e+08     3.524049      4.301036       24.298981   351.914129   \n",
       "min    8.670000e+03     6.981000      9.710000       43.790000   143.500000   \n",
       "25%    8.692180e+05    11.700000     16.170000       75.170000   420.300000   \n",
       "50%    9.060240e+05    13.370000     18.840000       86.240000   551.100000   \n",
       "75%    8.813129e+06    15.780000     21.800000      104.100000   782.700000   \n",
       "max    9.113205e+08    28.110000     39.280000      188.500000  2501.000000   \n",
       "\n",
       "       smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "count       569.000000        569.000000      569.000000           569.000000   \n",
       "mean          0.096360          0.104341        0.088799             0.048919   \n",
       "std           0.014064          0.052813        0.079720             0.038803   \n",
       "min           0.052630          0.019380        0.000000             0.000000   \n",
       "25%           0.086370          0.064920        0.029560             0.020310   \n",
       "50%           0.095870          0.092630        0.061540             0.033500   \n",
       "75%           0.105300          0.130400        0.130700             0.074000   \n",
       "max           0.163400          0.345400        0.426800             0.201200   \n",
       "\n",
       "       symmetry_mean  ...  texture_worst  perimeter_worst   area_worst  \\\n",
       "count     569.000000  ...     569.000000       569.000000   569.000000   \n",
       "mean        0.181162  ...      25.677223       107.261213   880.583128   \n",
       "std         0.027414  ...       6.146258        33.602542   569.356993   \n",
       "min         0.106000  ...      12.020000        50.410000   185.200000   \n",
       "25%         0.161900  ...      21.080000        84.110000   515.300000   \n",
       "50%         0.179200  ...      25.410000        97.660000   686.500000   \n",
       "75%         0.195700  ...      29.720000       125.400000  1084.000000   \n",
       "max         0.304000  ...      49.540000       251.200000  4254.000000   \n",
       "\n",
       "       smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "count        569.000000         569.000000       569.000000   \n",
       "mean           0.132369           0.254265         0.272188   \n",
       "std            0.022832           0.157336         0.208624   \n",
       "min            0.071170           0.027290         0.000000   \n",
       "25%            0.116600           0.147200         0.114500   \n",
       "50%            0.131300           0.211900         0.226700   \n",
       "75%            0.146000           0.339100         0.382900   \n",
       "max            0.222600           1.058000         1.252000   \n",
       "\n",
       "       concave points_worst  symmetry_worst  fractal_dimension_worst  \\\n",
       "count            569.000000      569.000000               569.000000   \n",
       "mean               0.114606        0.290076                 0.083946   \n",
       "std                0.065732        0.061867                 0.018061   \n",
       "min                0.000000        0.156500                 0.055040   \n",
       "25%                0.064930        0.250400                 0.071460   \n",
       "50%                0.099930        0.282200                 0.080040   \n",
       "75%                0.161400        0.317900                 0.092080   \n",
       "max                0.291000        0.663800                 0.207500   \n",
       "\n",
       "       Unnamed: 32  \n",
       "count          0.0  \n",
       "mean           NaN  \n",
       "std            NaN  \n",
       "min            NaN  \n",
       "25%            NaN  \n",
       "50%            NaN  \n",
       "75%            NaN  \n",
       "max            NaN  \n",
       "\n",
       "[8 rows x 32 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31944614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                           0\n",
       "diagnosis                    0\n",
       "radius_mean                  0\n",
       "texture_mean                 0\n",
       "perimeter_mean               0\n",
       "area_mean                    0\n",
       "smoothness_mean              0\n",
       "compactness_mean             0\n",
       "concavity_mean               0\n",
       "concave points_mean          0\n",
       "symmetry_mean                0\n",
       "fractal_dimension_mean       0\n",
       "radius_se                    0\n",
       "texture_se                   0\n",
       "perimeter_se                 0\n",
       "area_se                      0\n",
       "smoothness_se                0\n",
       "compactness_se               0\n",
       "concavity_se                 0\n",
       "concave points_se            0\n",
       "symmetry_se                  0\n",
       "fractal_dimension_se         0\n",
       "radius_worst                 0\n",
       "texture_worst                0\n",
       "perimeter_worst              0\n",
       "area_worst                   0\n",
       "smoothness_worst             0\n",
       "compactness_worst            0\n",
       "concavity_worst              0\n",
       "concave points_worst         0\n",
       "symmetry_worst               0\n",
       "fractal_dimension_worst      0\n",
       "Unnamed: 32                569\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9712146f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode the Categorical data\n",
    "df['diagnosis'] = df['diagnosis'].map({'B': 0, 'M': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02edc408",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Unnamed: 32'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4727c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>1</td>\n",
       "      <td>17.990</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.71190</td>\n",
       "      <td>0.26540</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>1</td>\n",
       "      <td>20.570</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.24160</td>\n",
       "      <td>0.18600</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>1</td>\n",
       "      <td>19.690</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.45040</td>\n",
       "      <td>0.24300</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>1</td>\n",
       "      <td>11.420</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.68690</td>\n",
       "      <td>0.25750</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>1</td>\n",
       "      <td>20.290</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.40000</td>\n",
       "      <td>0.16250</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>843786</td>\n",
       "      <td>1</td>\n",
       "      <td>12.450</td>\n",
       "      <td>15.70</td>\n",
       "      <td>82.57</td>\n",
       "      <td>477.1</td>\n",
       "      <td>0.12780</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.15780</td>\n",
       "      <td>0.08089</td>\n",
       "      <td>...</td>\n",
       "      <td>15.47</td>\n",
       "      <td>23.75</td>\n",
       "      <td>103.40</td>\n",
       "      <td>741.6</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>0.5249</td>\n",
       "      <td>0.53550</td>\n",
       "      <td>0.17410</td>\n",
       "      <td>0.3985</td>\n",
       "      <td>0.12440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>844359</td>\n",
       "      <td>1</td>\n",
       "      <td>18.250</td>\n",
       "      <td>19.98</td>\n",
       "      <td>119.60</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>0.09463</td>\n",
       "      <td>0.10900</td>\n",
       "      <td>0.11270</td>\n",
       "      <td>0.07400</td>\n",
       "      <td>...</td>\n",
       "      <td>22.88</td>\n",
       "      <td>27.66</td>\n",
       "      <td>153.20</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.37840</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.3063</td>\n",
       "      <td>0.08368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>84458202</td>\n",
       "      <td>1</td>\n",
       "      <td>13.710</td>\n",
       "      <td>20.83</td>\n",
       "      <td>90.20</td>\n",
       "      <td>577.9</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.16450</td>\n",
       "      <td>0.09366</td>\n",
       "      <td>0.05985</td>\n",
       "      <td>...</td>\n",
       "      <td>17.06</td>\n",
       "      <td>28.14</td>\n",
       "      <td>110.60</td>\n",
       "      <td>897.0</td>\n",
       "      <td>0.1654</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>0.26780</td>\n",
       "      <td>0.15560</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>0.11510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>844981</td>\n",
       "      <td>1</td>\n",
       "      <td>13.000</td>\n",
       "      <td>21.82</td>\n",
       "      <td>87.50</td>\n",
       "      <td>519.8</td>\n",
       "      <td>0.12730</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.18590</td>\n",
       "      <td>0.09353</td>\n",
       "      <td>...</td>\n",
       "      <td>15.49</td>\n",
       "      <td>30.73</td>\n",
       "      <td>106.20</td>\n",
       "      <td>739.3</td>\n",
       "      <td>0.1703</td>\n",
       "      <td>0.5401</td>\n",
       "      <td>0.53900</td>\n",
       "      <td>0.20600</td>\n",
       "      <td>0.4378</td>\n",
       "      <td>0.10720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>84501001</td>\n",
       "      <td>1</td>\n",
       "      <td>12.460</td>\n",
       "      <td>24.04</td>\n",
       "      <td>83.97</td>\n",
       "      <td>475.9</td>\n",
       "      <td>0.11860</td>\n",
       "      <td>0.23960</td>\n",
       "      <td>0.22730</td>\n",
       "      <td>0.08543</td>\n",
       "      <td>...</td>\n",
       "      <td>15.09</td>\n",
       "      <td>40.68</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.4</td>\n",
       "      <td>0.1853</td>\n",
       "      <td>1.0580</td>\n",
       "      <td>1.10500</td>\n",
       "      <td>0.22100</td>\n",
       "      <td>0.4366</td>\n",
       "      <td>0.20750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>845636</td>\n",
       "      <td>1</td>\n",
       "      <td>16.020</td>\n",
       "      <td>23.24</td>\n",
       "      <td>102.70</td>\n",
       "      <td>797.8</td>\n",
       "      <td>0.08206</td>\n",
       "      <td>0.06669</td>\n",
       "      <td>0.03299</td>\n",
       "      <td>0.03323</td>\n",
       "      <td>...</td>\n",
       "      <td>19.19</td>\n",
       "      <td>33.88</td>\n",
       "      <td>123.80</td>\n",
       "      <td>1150.0</td>\n",
       "      <td>0.1181</td>\n",
       "      <td>0.1551</td>\n",
       "      <td>0.14590</td>\n",
       "      <td>0.09975</td>\n",
       "      <td>0.2948</td>\n",
       "      <td>0.08452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>84610002</td>\n",
       "      <td>1</td>\n",
       "      <td>15.780</td>\n",
       "      <td>17.89</td>\n",
       "      <td>103.60</td>\n",
       "      <td>781.0</td>\n",
       "      <td>0.09710</td>\n",
       "      <td>0.12920</td>\n",
       "      <td>0.09954</td>\n",
       "      <td>0.06606</td>\n",
       "      <td>...</td>\n",
       "      <td>20.42</td>\n",
       "      <td>27.28</td>\n",
       "      <td>136.50</td>\n",
       "      <td>1299.0</td>\n",
       "      <td>0.1396</td>\n",
       "      <td>0.5609</td>\n",
       "      <td>0.39650</td>\n",
       "      <td>0.18100</td>\n",
       "      <td>0.3792</td>\n",
       "      <td>0.10480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>846226</td>\n",
       "      <td>1</td>\n",
       "      <td>19.170</td>\n",
       "      <td>24.80</td>\n",
       "      <td>132.40</td>\n",
       "      <td>1123.0</td>\n",
       "      <td>0.09740</td>\n",
       "      <td>0.24580</td>\n",
       "      <td>0.20650</td>\n",
       "      <td>0.11180</td>\n",
       "      <td>...</td>\n",
       "      <td>20.96</td>\n",
       "      <td>29.94</td>\n",
       "      <td>151.70</td>\n",
       "      <td>1332.0</td>\n",
       "      <td>0.1037</td>\n",
       "      <td>0.3903</td>\n",
       "      <td>0.36390</td>\n",
       "      <td>0.17670</td>\n",
       "      <td>0.3176</td>\n",
       "      <td>0.10230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>846381</td>\n",
       "      <td>1</td>\n",
       "      <td>15.850</td>\n",
       "      <td>23.95</td>\n",
       "      <td>103.70</td>\n",
       "      <td>782.7</td>\n",
       "      <td>0.08401</td>\n",
       "      <td>0.10020</td>\n",
       "      <td>0.09938</td>\n",
       "      <td>0.05364</td>\n",
       "      <td>...</td>\n",
       "      <td>16.84</td>\n",
       "      <td>27.66</td>\n",
       "      <td>112.00</td>\n",
       "      <td>876.5</td>\n",
       "      <td>0.1131</td>\n",
       "      <td>0.1924</td>\n",
       "      <td>0.23220</td>\n",
       "      <td>0.11190</td>\n",
       "      <td>0.2809</td>\n",
       "      <td>0.06287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>84667401</td>\n",
       "      <td>1</td>\n",
       "      <td>13.730</td>\n",
       "      <td>22.61</td>\n",
       "      <td>93.60</td>\n",
       "      <td>578.3</td>\n",
       "      <td>0.11310</td>\n",
       "      <td>0.22930</td>\n",
       "      <td>0.21280</td>\n",
       "      <td>0.08025</td>\n",
       "      <td>...</td>\n",
       "      <td>15.03</td>\n",
       "      <td>32.01</td>\n",
       "      <td>108.80</td>\n",
       "      <td>697.7</td>\n",
       "      <td>0.1651</td>\n",
       "      <td>0.7725</td>\n",
       "      <td>0.69430</td>\n",
       "      <td>0.22080</td>\n",
       "      <td>0.3596</td>\n",
       "      <td>0.14310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>84799002</td>\n",
       "      <td>1</td>\n",
       "      <td>14.540</td>\n",
       "      <td>27.54</td>\n",
       "      <td>96.73</td>\n",
       "      <td>658.8</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.15950</td>\n",
       "      <td>0.16390</td>\n",
       "      <td>0.07364</td>\n",
       "      <td>...</td>\n",
       "      <td>17.46</td>\n",
       "      <td>37.13</td>\n",
       "      <td>124.10</td>\n",
       "      <td>943.2</td>\n",
       "      <td>0.1678</td>\n",
       "      <td>0.6577</td>\n",
       "      <td>0.70260</td>\n",
       "      <td>0.17120</td>\n",
       "      <td>0.4218</td>\n",
       "      <td>0.13410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>848406</td>\n",
       "      <td>1</td>\n",
       "      <td>14.680</td>\n",
       "      <td>20.13</td>\n",
       "      <td>94.74</td>\n",
       "      <td>684.5</td>\n",
       "      <td>0.09867</td>\n",
       "      <td>0.07200</td>\n",
       "      <td>0.07395</td>\n",
       "      <td>0.05259</td>\n",
       "      <td>...</td>\n",
       "      <td>19.07</td>\n",
       "      <td>30.88</td>\n",
       "      <td>123.40</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>0.1464</td>\n",
       "      <td>0.1871</td>\n",
       "      <td>0.29140</td>\n",
       "      <td>0.16090</td>\n",
       "      <td>0.3029</td>\n",
       "      <td>0.08216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>84862001</td>\n",
       "      <td>1</td>\n",
       "      <td>16.130</td>\n",
       "      <td>20.68</td>\n",
       "      <td>108.10</td>\n",
       "      <td>798.8</td>\n",
       "      <td>0.11700</td>\n",
       "      <td>0.20220</td>\n",
       "      <td>0.17220</td>\n",
       "      <td>0.10280</td>\n",
       "      <td>...</td>\n",
       "      <td>20.96</td>\n",
       "      <td>31.48</td>\n",
       "      <td>136.80</td>\n",
       "      <td>1315.0</td>\n",
       "      <td>0.1789</td>\n",
       "      <td>0.4233</td>\n",
       "      <td>0.47840</td>\n",
       "      <td>0.20730</td>\n",
       "      <td>0.3706</td>\n",
       "      <td>0.11420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>849014</td>\n",
       "      <td>1</td>\n",
       "      <td>19.810</td>\n",
       "      <td>22.15</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1260.0</td>\n",
       "      <td>0.09831</td>\n",
       "      <td>0.10270</td>\n",
       "      <td>0.14790</td>\n",
       "      <td>0.09498</td>\n",
       "      <td>...</td>\n",
       "      <td>27.32</td>\n",
       "      <td>30.88</td>\n",
       "      <td>186.80</td>\n",
       "      <td>2398.0</td>\n",
       "      <td>0.1512</td>\n",
       "      <td>0.3150</td>\n",
       "      <td>0.53720</td>\n",
       "      <td>0.23880</td>\n",
       "      <td>0.2768</td>\n",
       "      <td>0.07615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8510426</td>\n",
       "      <td>0</td>\n",
       "      <td>13.540</td>\n",
       "      <td>14.36</td>\n",
       "      <td>87.46</td>\n",
       "      <td>566.3</td>\n",
       "      <td>0.09779</td>\n",
       "      <td>0.08129</td>\n",
       "      <td>0.06664</td>\n",
       "      <td>0.04781</td>\n",
       "      <td>...</td>\n",
       "      <td>15.11</td>\n",
       "      <td>19.26</td>\n",
       "      <td>99.70</td>\n",
       "      <td>711.2</td>\n",
       "      <td>0.1440</td>\n",
       "      <td>0.1773</td>\n",
       "      <td>0.23900</td>\n",
       "      <td>0.12880</td>\n",
       "      <td>0.2977</td>\n",
       "      <td>0.07259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>8510653</td>\n",
       "      <td>0</td>\n",
       "      <td>13.080</td>\n",
       "      <td>15.71</td>\n",
       "      <td>85.63</td>\n",
       "      <td>520.0</td>\n",
       "      <td>0.10750</td>\n",
       "      <td>0.12700</td>\n",
       "      <td>0.04568</td>\n",
       "      <td>0.03110</td>\n",
       "      <td>...</td>\n",
       "      <td>14.50</td>\n",
       "      <td>20.49</td>\n",
       "      <td>96.09</td>\n",
       "      <td>630.5</td>\n",
       "      <td>0.1312</td>\n",
       "      <td>0.2776</td>\n",
       "      <td>0.18900</td>\n",
       "      <td>0.07283</td>\n",
       "      <td>0.3184</td>\n",
       "      <td>0.08183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>8510824</td>\n",
       "      <td>0</td>\n",
       "      <td>9.504</td>\n",
       "      <td>12.44</td>\n",
       "      <td>60.34</td>\n",
       "      <td>273.9</td>\n",
       "      <td>0.10240</td>\n",
       "      <td>0.06492</td>\n",
       "      <td>0.02956</td>\n",
       "      <td>0.02076</td>\n",
       "      <td>...</td>\n",
       "      <td>10.23</td>\n",
       "      <td>15.66</td>\n",
       "      <td>65.13</td>\n",
       "      <td>314.9</td>\n",
       "      <td>0.1324</td>\n",
       "      <td>0.1148</td>\n",
       "      <td>0.08867</td>\n",
       "      <td>0.06227</td>\n",
       "      <td>0.2450</td>\n",
       "      <td>0.07773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>8511133</td>\n",
       "      <td>1</td>\n",
       "      <td>15.340</td>\n",
       "      <td>14.26</td>\n",
       "      <td>102.50</td>\n",
       "      <td>704.4</td>\n",
       "      <td>0.10730</td>\n",
       "      <td>0.21350</td>\n",
       "      <td>0.20770</td>\n",
       "      <td>0.09756</td>\n",
       "      <td>...</td>\n",
       "      <td>18.07</td>\n",
       "      <td>19.08</td>\n",
       "      <td>125.10</td>\n",
       "      <td>980.9</td>\n",
       "      <td>0.1390</td>\n",
       "      <td>0.5954</td>\n",
       "      <td>0.63050</td>\n",
       "      <td>0.23930</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.09946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>851509</td>\n",
       "      <td>1</td>\n",
       "      <td>21.160</td>\n",
       "      <td>23.04</td>\n",
       "      <td>137.20</td>\n",
       "      <td>1404.0</td>\n",
       "      <td>0.09428</td>\n",
       "      <td>0.10220</td>\n",
       "      <td>0.10970</td>\n",
       "      <td>0.08632</td>\n",
       "      <td>...</td>\n",
       "      <td>29.17</td>\n",
       "      <td>35.59</td>\n",
       "      <td>188.00</td>\n",
       "      <td>2615.0</td>\n",
       "      <td>0.1401</td>\n",
       "      <td>0.2600</td>\n",
       "      <td>0.31550</td>\n",
       "      <td>0.20090</td>\n",
       "      <td>0.2822</td>\n",
       "      <td>0.07526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>852552</td>\n",
       "      <td>1</td>\n",
       "      <td>16.650</td>\n",
       "      <td>21.38</td>\n",
       "      <td>110.00</td>\n",
       "      <td>904.6</td>\n",
       "      <td>0.11210</td>\n",
       "      <td>0.14570</td>\n",
       "      <td>0.15250</td>\n",
       "      <td>0.09170</td>\n",
       "      <td>...</td>\n",
       "      <td>26.46</td>\n",
       "      <td>31.56</td>\n",
       "      <td>177.00</td>\n",
       "      <td>2215.0</td>\n",
       "      <td>0.1805</td>\n",
       "      <td>0.3578</td>\n",
       "      <td>0.46950</td>\n",
       "      <td>0.20950</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.09564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0     842302          1       17.990         10.38          122.80     1001.0   \n",
       "1     842517          1       20.570         17.77          132.90     1326.0   \n",
       "2   84300903          1       19.690         21.25          130.00     1203.0   \n",
       "3   84348301          1       11.420         20.38           77.58      386.1   \n",
       "4   84358402          1       20.290         14.34          135.10     1297.0   \n",
       "5     843786          1       12.450         15.70           82.57      477.1   \n",
       "6     844359          1       18.250         19.98          119.60     1040.0   \n",
       "7   84458202          1       13.710         20.83           90.20      577.9   \n",
       "8     844981          1       13.000         21.82           87.50      519.8   \n",
       "9   84501001          1       12.460         24.04           83.97      475.9   \n",
       "10    845636          1       16.020         23.24          102.70      797.8   \n",
       "11  84610002          1       15.780         17.89          103.60      781.0   \n",
       "12    846226          1       19.170         24.80          132.40     1123.0   \n",
       "13    846381          1       15.850         23.95          103.70      782.7   \n",
       "14  84667401          1       13.730         22.61           93.60      578.3   \n",
       "15  84799002          1       14.540         27.54           96.73      658.8   \n",
       "16    848406          1       14.680         20.13           94.74      684.5   \n",
       "17  84862001          1       16.130         20.68          108.10      798.8   \n",
       "18    849014          1       19.810         22.15          130.00     1260.0   \n",
       "19   8510426          0       13.540         14.36           87.46      566.3   \n",
       "20   8510653          0       13.080         15.71           85.63      520.0   \n",
       "21   8510824          0        9.504         12.44           60.34      273.9   \n",
       "22   8511133          1       15.340         14.26          102.50      704.4   \n",
       "23    851509          1       21.160         23.04          137.20     1404.0   \n",
       "24    852552          1       16.650         21.38          110.00      904.6   \n",
       "\n",
       "    smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0           0.11840           0.27760         0.30010              0.14710   \n",
       "1           0.08474           0.07864         0.08690              0.07017   \n",
       "2           0.10960           0.15990         0.19740              0.12790   \n",
       "3           0.14250           0.28390         0.24140              0.10520   \n",
       "4           0.10030           0.13280         0.19800              0.10430   \n",
       "5           0.12780           0.17000         0.15780              0.08089   \n",
       "6           0.09463           0.10900         0.11270              0.07400   \n",
       "7           0.11890           0.16450         0.09366              0.05985   \n",
       "8           0.12730           0.19320         0.18590              0.09353   \n",
       "9           0.11860           0.23960         0.22730              0.08543   \n",
       "10          0.08206           0.06669         0.03299              0.03323   \n",
       "11          0.09710           0.12920         0.09954              0.06606   \n",
       "12          0.09740           0.24580         0.20650              0.11180   \n",
       "13          0.08401           0.10020         0.09938              0.05364   \n",
       "14          0.11310           0.22930         0.21280              0.08025   \n",
       "15          0.11390           0.15950         0.16390              0.07364   \n",
       "16          0.09867           0.07200         0.07395              0.05259   \n",
       "17          0.11700           0.20220         0.17220              0.10280   \n",
       "18          0.09831           0.10270         0.14790              0.09498   \n",
       "19          0.09779           0.08129         0.06664              0.04781   \n",
       "20          0.10750           0.12700         0.04568              0.03110   \n",
       "21          0.10240           0.06492         0.02956              0.02076   \n",
       "22          0.10730           0.21350         0.20770              0.09756   \n",
       "23          0.09428           0.10220         0.10970              0.08632   \n",
       "24          0.11210           0.14570         0.15250              0.09170   \n",
       "\n",
       "    ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0   ...         25.38          17.33           184.60      2019.0   \n",
       "1   ...         24.99          23.41           158.80      1956.0   \n",
       "2   ...         23.57          25.53           152.50      1709.0   \n",
       "3   ...         14.91          26.50            98.87       567.7   \n",
       "4   ...         22.54          16.67           152.20      1575.0   \n",
       "5   ...         15.47          23.75           103.40       741.6   \n",
       "6   ...         22.88          27.66           153.20      1606.0   \n",
       "7   ...         17.06          28.14           110.60       897.0   \n",
       "8   ...         15.49          30.73           106.20       739.3   \n",
       "9   ...         15.09          40.68            97.65       711.4   \n",
       "10  ...         19.19          33.88           123.80      1150.0   \n",
       "11  ...         20.42          27.28           136.50      1299.0   \n",
       "12  ...         20.96          29.94           151.70      1332.0   \n",
       "13  ...         16.84          27.66           112.00       876.5   \n",
       "14  ...         15.03          32.01           108.80       697.7   \n",
       "15  ...         17.46          37.13           124.10       943.2   \n",
       "16  ...         19.07          30.88           123.40      1138.0   \n",
       "17  ...         20.96          31.48           136.80      1315.0   \n",
       "18  ...         27.32          30.88           186.80      2398.0   \n",
       "19  ...         15.11          19.26            99.70       711.2   \n",
       "20  ...         14.50          20.49            96.09       630.5   \n",
       "21  ...         10.23          15.66            65.13       314.9   \n",
       "22  ...         18.07          19.08           125.10       980.9   \n",
       "23  ...         29.17          35.59           188.00      2615.0   \n",
       "24  ...         26.46          31.56           177.00      2215.0   \n",
       "\n",
       "    smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0             0.1622             0.6656          0.71190   \n",
       "1             0.1238             0.1866          0.24160   \n",
       "2             0.1444             0.4245          0.45040   \n",
       "3             0.2098             0.8663          0.68690   \n",
       "4             0.1374             0.2050          0.40000   \n",
       "5             0.1791             0.5249          0.53550   \n",
       "6             0.1442             0.2576          0.37840   \n",
       "7             0.1654             0.3682          0.26780   \n",
       "8             0.1703             0.5401          0.53900   \n",
       "9             0.1853             1.0580          1.10500   \n",
       "10            0.1181             0.1551          0.14590   \n",
       "11            0.1396             0.5609          0.39650   \n",
       "12            0.1037             0.3903          0.36390   \n",
       "13            0.1131             0.1924          0.23220   \n",
       "14            0.1651             0.7725          0.69430   \n",
       "15            0.1678             0.6577          0.70260   \n",
       "16            0.1464             0.1871          0.29140   \n",
       "17            0.1789             0.4233          0.47840   \n",
       "18            0.1512             0.3150          0.53720   \n",
       "19            0.1440             0.1773          0.23900   \n",
       "20            0.1312             0.2776          0.18900   \n",
       "21            0.1324             0.1148          0.08867   \n",
       "22            0.1390             0.5954          0.63050   \n",
       "23            0.1401             0.2600          0.31550   \n",
       "24            0.1805             0.3578          0.46950   \n",
       "\n",
       "    concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.26540          0.4601                  0.11890  \n",
       "1                0.18600          0.2750                  0.08902  \n",
       "2                0.24300          0.3613                  0.08758  \n",
       "3                0.25750          0.6638                  0.17300  \n",
       "4                0.16250          0.2364                  0.07678  \n",
       "5                0.17410          0.3985                  0.12440  \n",
       "6                0.19320          0.3063                  0.08368  \n",
       "7                0.15560          0.3196                  0.11510  \n",
       "8                0.20600          0.4378                  0.10720  \n",
       "9                0.22100          0.4366                  0.20750  \n",
       "10               0.09975          0.2948                  0.08452  \n",
       "11               0.18100          0.3792                  0.10480  \n",
       "12               0.17670          0.3176                  0.10230  \n",
       "13               0.11190          0.2809                  0.06287  \n",
       "14               0.22080          0.3596                  0.14310  \n",
       "15               0.17120          0.4218                  0.13410  \n",
       "16               0.16090          0.3029                  0.08216  \n",
       "17               0.20730          0.3706                  0.11420  \n",
       "18               0.23880          0.2768                  0.07615  \n",
       "19               0.12880          0.2977                  0.07259  \n",
       "20               0.07283          0.3184                  0.08183  \n",
       "21               0.06227          0.2450                  0.07773  \n",
       "22               0.23930          0.4667                  0.09946  \n",
       "23               0.20090          0.2822                  0.07526  \n",
       "24               0.20950          0.3613                  0.09564  \n",
       "\n",
       "[25 rows x 32 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b73da749",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature selection\n",
    "X= df.drop(columns=['diagnosis']) #Independent variables\n",
    "y= df['diagnosis'] #Target or Dependent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a35945a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into Train and Test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71aaa118",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8721ca90",
   "metadata": {},
   "source": [
    "# Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef20e79f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the Model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87c6e27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make Predictions\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae80200",
   "metadata": {},
   "source": [
    "#Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ea5adf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "#Accuracy Score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "934bbeec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Confusion Matrix\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(matrix, annot=True, cmap=\"Blues\",fmt=\"d\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f1eb78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98        71\n",
      "           1       0.98      0.95      0.96        43\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification Report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a92298",
   "metadata": {},
   "source": [
    "# Improve the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a842823f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 0.1, 'solver': 'liblinear'}\n",
      "Improved Model Accuracy: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweet\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\sweet\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\sweet\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\sweet\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\sweet\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'solver': ['liblinear', 'lbfgs']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "\n",
    "# Evaluate the Best Model\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "print(f\"Improved Model Accuracy: {accuracy_score(y_test, y_pred_best):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f676afc",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4f927b",
   "metadata": {},
   "source": [
    "=> High Model Accuracy: The logistic regression model achieved an accuracy of 97%, demonstrating its strong predictive power in distinguishing between benign and malignant cancer cases.\n",
    "\n",
    "=> Effective Feature Scaling: Standardization of features using StandardScaler() improved the model's efficiency and stability, ensuring better convergence during training.\n",
    "\n",
    "=> Strong Performance Metrics:\n",
    "-Precision: 97% for class 0 (benign) and 98% for class 1 (malignant), indicating low false positive rates.\n",
    "-Recall: 99% for class 0 and 95% for class 1, meaning the model correctly identified most cancerous cases.\n",
    "-F1-score: Balanced performance for both classes, confirming a well-optimized model.\n",
    "\n",
    "=> Confusion Matrix Insights:\n",
    "A low number of misclassifications, proving the model’s reliability.\n",
    "More false negatives than false positives, which highlights the importance of further optimizing recall for malignant cases.\n",
    "\n",
    "=> Hyperparameter Tuning Success: Grid search optimization identified the best parameters (C=0.1, solver='liblinear'), leading to an improved accuracy of 99%, making the model even more robust.\n",
    "\n",
    "=> Potential for Further Improvements:\n",
    "-Handling Imbalance: If data is imbalanced, techniques like SMOTE (Synthetic Minority Over-sampling) can further enhance performance.\n",
    "-Feature Selection: Analyzing feature importance can help remove less significant variables, reducing complexity.\n",
    "-Ensemble Methods: Combining logistic regression with Random Forest or XGBoost could enhance predictive capability.\n",
    "\n",
    "=> Real-World Applicability: Given its simplicity, interpretability, and high accuracy, this model can serve as a valuable diagnostic tool in early cancer detection, assisting healthcare professionals in decision-making."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
